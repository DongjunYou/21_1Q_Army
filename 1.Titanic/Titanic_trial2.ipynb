{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic_trial2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPsu6kXGeO+/iA93Riv19Gk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lutris98/21_1Q/blob/master/1.Titanic/Titanic_trial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaDmu6d-9pwA"
      },
      "source": [
        "# 1. EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNOjOEZEge3O"
      },
      "source": [
        "import pandas as pd \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV #model_selection doesn't need mentioning, only the method does\r\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\r\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\r\n",
        "from xgboost import XGBClassifier\r\n",
        "from lightgbm import LGBMClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import accuracy_score #given metric was accuracy\r\n"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5WPdAAm0Qsy",
        "outputId": "fc610d73-0a28-48c3-cbca-1038cb59ea6f"
      },
      "source": [
        "from google.colab import drive #Korean Army banned me from using os resources so I learned new ways\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "titanic_df=pd.read_csv('/content/gdrive/MyDrive/Dataset/titanic_train.csv') "
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "XNwPVclMMOJT",
        "outputId": "1a884e46-e3d0-40d5-95cd-dac7c7ef2709"
      },
      "source": [
        "titanic_df.head(3) "
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "\n",
              "[3 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGCRXDRJ3kA9",
        "outputId": "438828c6-5d85-40c4-8b33-61a2924c28d8"
      },
      "source": [
        "print(titanic_df.info()) #objects are strings"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwrGPAnD4zXu"
      },
      "source": [
        "titanic_feature=titanic_df.drop(['Survived'], axis=1) #parameter axis is mandatory\r\n",
        "titanic_label=titanic_df['Survived']"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGUl6OZO90ya"
      },
      "source": [
        "#2. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hZHp8aYBSdj",
        "outputId": "7b8fa136-9652-4780-9698-2158ce83bbff"
      },
      "source": [
        "titanic_feature=titanic_feature.drop(['Name', 'Ticket'], axis=1) #1 #PassengerId will be useless but it is how the result should find people #drop method doesn't allow inplacing(Should check results along the way)\r\n",
        "titanic_feature['Age'].fillna(titanic_feature['Age'].mean(), inplace=True) #could be affecting, so average would minimize the loss(for further development, something could be inferred from sibsp&parch)\r\n",
        "titanic_feature['Cabin'].fillna('N', inplace=True) #inplacing so that additional object would be unnecesory\r\n",
        "titanic_feature['Embarked'].fillna('N',inplace=True) #Wonder features like this would be better off set random...\r\n",
        "print(titanic_feature.isnull().sum().sum()) #checking"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObS8b057FfAm",
        "outputId": "5682c634-0c50-431e-f28a-d280212f93ed"
      },
      "source": [
        "print('Sex distribution:\\n',titanic_feature['Sex'].value_counts()) #focusing on columns\r\n",
        "print('Cabin distribution\\n',titanic_feature['Cabin'].value_counts())\r\n",
        "print('Embarked distribution:\\n',titanic_feature['Embarked'].value_counts())"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sex distribution:\n",
            " male      577\n",
            "female    314\n",
            "Name: Sex, dtype: int64\n",
            "Cabin distribution\n",
            " N              687\n",
            "C23 C25 C27      4\n",
            "B96 B98          4\n",
            "G6               4\n",
            "D                3\n",
            "              ... \n",
            "C47              1\n",
            "C118             1\n",
            "B30              1\n",
            "A26              1\n",
            "C85              1\n",
            "Name: Cabin, Length: 148, dtype: int64\n",
            "Embarked distribution:\n",
            " S    644\n",
            "C    168\n",
            "Q     77\n",
            "N      2\n",
            "Name: Embarked, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trpeRTyOG1nB"
      },
      "source": [
        "titanic_feature['Cabin']=titanic_df['Cabin'].str[:1] #Cabin needs insight that only the first character contains information #pd.str is applicable to series\r\n",
        "features=['Cabin','Sex','Embarked']\r\n",
        "for feature in features:\r\n",
        "  titanic_feature[feature]=LabelEncoder().fit_transform(titanic_feature[feature].astype(str)) #changing dtype of series"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPEjfjGrKtOr"
      },
      "source": [
        "#3. Cross validation & Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWHUJvRiK1ji"
      },
      "source": [
        "rf_clf=RandomForestClassifier(random_state=0) #Cross validation need models \r\n",
        "xgb_clf=XGBClassifier(random_state=0)\r\n",
        "lgbm_clf=LGBMClassifier(random_state=0)\r\n",
        "lr_clf=LogisticRegression(random_state=0, max_iter=5000)\r\n",
        "X_train, X_test, y_train, y_test=train_test_split(titanic_feature, titanic_label, test_size=0.1,random_state=0)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkrHw-VNbTv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d2aa2cb-86fb-493c-a310-f635dfb43921"
      },
      "source": [
        "rf_params={'n_estimators':[200,300],\r\n",
        "           'max_depth':[6,8,10,12], #similar to decisiontree\r\n",
        "           'min_samples_leaf':[3,5,7],\r\n",
        "           'min_samples_split':[10,15,20]}\r\n",
        "rf_gridcv=GridSearchCV(rf_clf, param_grid=rf_params, cv=5, n_jobs=-1) #using all CPU cores\r\n",
        "rf_gridcv.fit(X_train, y_train)\r\n",
        "print('best parameters:\\n',rf_gridcv.best_params_)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:\n",
            " {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 300}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJtKJuQ-e0Ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2c910e-b526-4082-ba09-84b517b5c071"
      },
      "source": [
        "lgbm_params={'n_estimators':[200,300],\r\n",
        "             'num_leaves':[32,64],\r\n",
        "             'min_child_samples':[60,100],\r\n",
        "             'subsample':[0.8,1],\r\n",
        "             'max_depth':[10]}\r\n",
        "lgbm_gridcv=GridSearchCV(lgbm_clf, param_grid=lgbm_params, cv=5, n_jobs=-1) \r\n",
        "lgbm_gridcv.fit(X_train, y_train)\r\n",
        "print('best parameters:\\n',lgbm_gridcv.best_params_)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:\n",
            " {'max_depth': 10, 'min_child_samples': 100, 'n_estimators': 200, 'num_leaves': 32, 'subsample': 0.8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LMoIOOjO49y",
        "outputId": "5bfacbb7-6d83-4c70-a90c-d017c63938c8"
      },
      "source": [
        "lr_params={'C':[0.1,1,10]}\r\n",
        "lr_gridcv=GridSearchCV(lr_clf, param_grid=lr_params, cv=5, n_jobs=-1) \r\n",
        "lr_gridcv.fit(X_train, y_train)\r\n",
        "print('best parameters:\\n',lr_gridcv.best_params_)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:\n",
            " {'C': 0.1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1unUXEw_NMcH"
      },
      "source": [
        "#4. modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjxu0w-0NQI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb8be789-f958-4519-9064-b3108723f01b"
      },
      "source": [
        "rf_clf=RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_leaf=3, min_samples_split=10, random_state=0) #Cross validation need models \r\n",
        "xgb_clf=XGBClassifier(n_estimators=200, max_depth=10,learning_rate=0.1)\r\n",
        "lgbm_clf=LGBMClassifier(n_estimators=300, num_leaves=32, min_child_samples=100, subsample=0.8, max_depth=10, random_state=0)\r\n",
        "lr_clf=LogisticRegression(C=0.1)\r\n",
        "vo_clf=VotingClassifier(estimators=[('RandomForest',rf_clf),('XGBoost',xgb_clf),('LightGBM',lgbm_clf),('LogisticRegression',lr_clf)], voting='soft')\r\n",
        "vo_clf.fit(X_train, y_train)\r\n",
        "pred1=rf_clf.fit(X_train, y_train).predict(X_test)\r\n",
        "pred2=xgb_clf.fit(X_train, y_train).predict(X_test)\r\n",
        "pred3=lgbm_clf.fit(X_train, y_train).predict(X_test)\r\n",
        "pred4=lr_clf.fit(X_train, y_train).predict(X_test)\r\n",
        "pred5=vo_clf.predict(X_test)\r\n",
        "print('Accuracy1:{0:.4f} Accuracy2:{1:.4f} Accuracy3:{2:4f} Accuracy4:{3:4f}'.format(accuracy_score(y_test,pred1), accuracy_score(y_test,pred2),accuracy_score(y_test,pred3),accuracy_score(y_test,pred4)))\r\n",
        "print('Final accuracy:{0:.4f}'.format(accuracy_score(y_test,pred5))) #from python3.6 should use fstring formatting  #:separates index and the number"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy1:0.8333 Accuracy2:0.8444 Accuracy3:0.855556 Accuracy4:0.766667\n",
            "Final accuracy:0.8333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOXTJAG5nVdH"
      },
      "source": [
        "# 1) Uploading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvKx24sQnlXR",
        "outputId": "073ab47a-0ee2-4bff-a419-95fd6aaf62cd"
      },
      "source": [
        "from google.colab import drive \r\n",
        "drive.mount('/content/gdrive')\r\n",
        "test_df=pd.read_csv('/content/gdrive/MyDrive/Dataset/titanic_test.csv') \r\n",
        "test_df.info()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Name         418 non-null    object \n",
            " 3   Sex          418 non-null    object \n",
            " 4   Age          332 non-null    float64\n",
            " 5   SibSp        418 non-null    int64  \n",
            " 6   Parch        418 non-null    int64  \n",
            " 7   Ticket       418 non-null    object \n",
            " 8   Fare         417 non-null    float64\n",
            " 9   Cabin        91 non-null     object \n",
            " 10  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 36.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs_hGd2xoL22"
      },
      "source": [
        "test_df=test_df.drop(['Name', 'Ticket'], axis=1) #uploading needs the same preprocessing I did on training set(but no need to split feature&label)\r\n",
        "test_df['Age'].fillna(test_df['Age'].mean(), inplace=True) \r\n",
        "test_df['Fare'].fillna(test_df['Fare'].mean(), inplace=True) \r\n",
        "test_df['Cabin'].fillna('N', inplace=True) \r\n",
        "test_df['Cabin']=test_df['Cabin'].str[:1] \r\n",
        "features=['Cabin','Sex','Embarked']\r\n",
        "for feature in features:\r\n",
        "  test_df[feature]=LabelEncoder().fit_transform(test_df[feature].astype(str)) \r\n",
        "realpred=vo_clf.predict(test_df) #output of classifier is ndarray object\r\n",
        "realpred=pd.DataFrame(realpred, columns=['Survived']) #never forget[]\r\n",
        "Submit=pd.DataFrame({'PassengerId':test_df['PassengerId'],'Survived':realpred['Survived']}) #Data set by giving each column name and data\r\n",
        "Submit.head(3)\r\n",
        "Submit.to_csv('/content/gdrive/MyDrive/Dataset/Lutris_titanic.csv', index = False) #The client doesn't want indice on submission"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXVyEpanGSr5"
      },
      "source": [
        "# 2) Feedback<br>\r\n"
      ]
    }
  ]
}